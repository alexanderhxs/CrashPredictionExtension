Here are the additional files/changes for the atlas-benchmark, to reconstruct the experiments

# Extending the Atlas-Benchmark Framework for the MMCP Dataset

This folder is the extension of the original [Atlas-Benchmark Framework](https://github.com/boschresearch/the-atlas-benchmark). It has been adapted to process and evaluate the custom **MMCP (Multi-modal-Crash-Prediction)** dataset. Additionally, the **Trajectron++** model has been integrated for advanced prediction analysis.

## Overview of New Components

The following files and folders have been added or modified to enable the new functionality:

-   **`dataset/`**: This folder contains the raw data files of the MMCP dataset. Unlike the standard datasets (ETH, UCY) from the original repository, these are custom recordings.
-   **`dataset_config_mmcp.yaml`**: A new configuration file created specifically for the MMCP dataset. It defines how the data should be loaded and preprocessed.
-   **`data_evaluation.ipynb`**: A new Jupyter Notebook that serves as the central tool for analysis. It performs a quantitative evaluation and a direct comparison between a simple baseline model (CVM) and the complex Trajectron++ model on the MMCP dataset.

---

## 1. MMCP Dataset and Configuration

### `dataset/`
This folder houses the `.json` files of the MMCP dataset. The structure is designed to be read by the framework's `Dataset` object.

### `dataset_config_mmcp.yaml`
This file is crucial for integrating the new dataset. It instructs the framework on how to handle the data.

**Key Parameters:**
-   **`name: mmcp`**: Defines the name of the dataset.
-   **`path:`**: Lists the paths to the individual `.json` files in the `dataset/` folder.
-   **`frequency: 2.5`**: Specifies the recording frequency of the data in Hz.
-   **`observation period: 6`**: Defines that 6 past frames are used as the observation (input) for the models.
-   **`prediction horizon: 3`**: Defines that the models should predict 3 future frames.

This configuration allows the `Dataset` class from the original framework to be used without modification to load the new data and generate "Rolling Prediction" scenarios.

---

## 2. Trajectron++ Integration

To enable advanced, learning-based predictions, the **Trajectron++** model from the [official StanfordASL repository](https://github.com/StanfordASL/Trajectron-plus-plus) has been integrated.

### Used Version
The model is based on the **ECCV 2020** version of the Trajectron++ code. The integration is achieved through a wrapper that facilitates communication between the Atlas framework and the Trajectron++ model.

### Integration Mechanism
1.  **Code Base**: The `Trajectron-plus-plus` folder is a copy of the original repository.
2.  **Wrapper Class**: The `TrajectronPredictor` class (defined in `src/predict/predict_trajectronpp.py`) acts as a bridge. It is instantiated in the `data_evaluation.ipynb` notebook.
3.  **Data Conversion**: The `TrajectronPredictor` accepts a `Scenario` object from the Atlas framework. It converts the observation data (past trajectories) into the format required by Trajectron++ (scene graphs, nodes, etc.).
4.  **Prediction**: The wrapper calls the `predict` method of the Trajectron++ model to generate the future trajectories.
5.  **Back-Conversion**: The predictions from Trajectron++ are converted back into the `Prediction` format of the Atlas framework, allowing them to be processed by the `Evaluator`.

This approach allows the powerful Trajectron++ model to be seamlessly integrated into the existing evaluation workflow of the Atlas benchmark.

---

## 3. Evaluation Notebook: `data_evaluation.ipynb`

This notebook is the centerpiece of the analysis. It demonstrates the entire process, from data generation to final evaluation.

### Workflow
1.  **Load Data**: The notebook loads the MMCP dataset using the `dataset_config_mmcp.yaml`.
2.  **Extract Scenarios**: All possible scenarios are extracted from the entire dataset.
3.  **Initialize Predictors**:
    -   A **Constant Velocity Model (CVM)** is instantiated as `Predictor_kara`. This serves as a simple but important baseline.
    -   A **Trajectron++** model is loaded via the `TrajectronPredictor` wrapper.
4.  **Quantitative Evaluation**:
    -   The notebook iterates through **every single scenario** in the dataset.
    -   For each scenario, a prediction is generated by both CVM and Trajectron++.
    -   The `Evaluator` class calculates the **ADE**, **FDE**, **kADE**, and **kFDE** metrics.
5.  **Result Analysis**:
    -   At the end, the mean and standard deviation for all metrics are printed for both models. This allows for a direct and fair comparison of their prediction accuracy across the entire MMCP dataset.
    -   The results show that Trajectron++ achieves significantly higher accuracy than the CVM.

### Visualization
In addition to the quantitative analysis, the notebook offers the ability to visually inspect the predictions for any selected scenario. The `evaluation.plot_scenario()` function draws the observed trajectory, the ground-truth future, and the models' predictions, providing qualitative insight into the models' behavior.



# Setup and Installation

This guide provides instructions for setting up the necessary environment to run the experiments in this repository. It is highly recommended to use a virtual environment to avoid conflicts with other Python projects.

## 1. Prerequisites

-   **Python:** This project is best run with **Python 3.8**. While other versions might work, 3.8 is recommended for compatibility with all dependencies, especially PyTorch.
-   **Git:** To clone the repository.
-   **(Optional) NVIDIA GPU with CUDA:** To get the best performance from the Trajectron++ model, an NVIDIA GPU with a compatible CUDA toolkit is required.

## 2. Environment Setup

1.  **Clone the repository:**
    ```bash
    git clone <your-repository-url>
    cd <repository-folder>
    ```

2.  **Create and activate a virtual environment:**

    *   On **Windows**:
        ```bash
        python -m venv venv
        .\venv\Scripts\activate
        ```
    *   On **macOS/Linux**:
        ```bash
        python3 -m venv venv
        source venv/bin/activate
        ```

## 3. Installing Dependencies

### Step 3.1: Install PyTorch (Special Instructions)

**Do not** add `torch` or `torchvision` to the `requirements.txt` file directly. The correct installation command depends on your operating system and whether you have a CUDA-enabled GPU.

1.  Visit the official PyTorch website: [https://pytorch.org/get-started/locally/](https://pytorch.org/get-started/locally/)

2.  Use the interactive tool on the website to select your system's configuration (e.g., Stable, Windows/Linux, Pip, Python, CUDA version or CPU).

3.  Copy the generated command and run it in your activated virtual environment.

    *   **Example for CPU-only on Windows/Linux:**
        ```bash
        pip install torch torchvision torchaudio
        ```
    *   **Example for CUDA 11.8 on Windows/Linux:**
        ```bash
        pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118
        ```

**Why is this necessary?**
PyTorch needs to be compiled against the specific CUDA toolkit installed on your system to leverage the GPU. The standard `pip install torch` command often installs a CPU-only version, which will cause the Trajectron++ model to run very slowly or fail if it expects a GPU. The official PyTorch website provides the correct package URL for your specific hardware setup.

### Step 3.2: Install Remaining Packages

Once PyTorch is installed correctly, you can install all the other packages from your `requirements.txt` file with a single command:

```bash
pip install -r requirements.txt
```

After completing these steps, your environment is ready. You can now launch the Jupyter Notebooks (e.g., `data_evaluation.ipynb`) to run the analyses.
```bash
jupyter notebook
```
